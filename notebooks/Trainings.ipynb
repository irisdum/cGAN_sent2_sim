{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select training_env as the kernel (Kernel -> change kernel) . If it is not available, refer to the README.md section Training a model. You will need to install the anaconda environment :  training_env.\n",
    "Change the path in the Notebook.\n",
    "Moreover to check in realtime the evolution of the loss and metrics look at the README.md section detailling the process with Tensorboard. The saved logs will be at the location PATH_THIS_TRAINING+\"logs\"\n",
    "Eventually to visualize the image generated look at the notebook Visualize_training_data.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/idumeur/code\") # CHANGE\n",
    "sys.path.append(\"/home/idumeur/code/cGAN_sent2_sim/\") #CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_dataset import load_data\n",
    "from models import clean_gan\n",
    "from train import open_yaml,saving_yaml\n",
    "\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/srv/osirim/idumeur/data/dataset6/prepro1/input_large_dataset/\" #path to the dataset which contains the tile for the training\n",
    "PATH_TRAININGS=\"/srv/osirim/idumeur/trainings/\"\n",
    "NAME_MODEL=\"test_model\" #name of the model\n",
    "TRAINING_NBER=\"100\" #Id of the training, to change\n",
    "PATH_THIS_MODEL=PATH_TRAININGS+NAME_MODEL+\"/\"\n",
    "PATH_THIS_TRAINING=\"{}{}/training_{}/\".format(PATH_TRAININGS,NAME_MODEL,TRAINING_NBER)\n",
    "PATH_CHECKPOINT=\"{}checkpoints/\".format(PATH_THIS_TRAINING)\n",
    "PATH_SAVED_IM=\"{}saved_training_images/\".format(PATH_THIS_TRAINING)\n",
    "PATH_TRAIN_YAML=\"/home/idumeur/code/sent2_cloud_remover/GAN_confs/train.yaml\" #The based configuratiion file for the training param\n",
    "PATH_MODEL_YAML=\"/home/idumeur/code/sent2_cloud_remover/GAN_confs/model.yaml\" #The based configuratiion file for the model param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/idumeur/code/cGAN_sent2_sim/train.py:105: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  return yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "train_param=open_yaml(PATH_TRAIN_YAML) #dict\n",
    "model_param=open_yaml(PATH_MODEL_YAML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param[\"model_name\"]=NAME_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "here are the current parameters for the discriminator convolutional layers. You can change them by setting by model_param[\"dict_discri_archi\"]= new_dictionnary. In the dictionnary, keys are the number of the conv layer, and the list corresponds respectively to [\"padding\",\"stride\",\"kernel\",\"nfilter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [1, 2, 4, 64],\n",
       " 2: [1, 2, 4, 256],\n",
       " 3: [1, 2, 4, 256],\n",
       " 4: [1, 1, 4, 512],\n",
       " 5: [1, 1, 4, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param[\"dict_discri_archi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sigmoid'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param[\"d_last_activ\"] #The last activation of the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Training parameters\n",
    "train_param[\"train_directory\"]=PATH+\"train/\" #path to the train data\n",
    "train_param[\"val_directory\"]=PATH+\"val/\" #path to the val data\n",
    "train_param[\"training_number\"]=TRAINING_NBER #id of the training\n",
    "train_param[\"epoch\"]=500 #max nber of epochs\n",
    "train_param[\"lr\"]=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_param[\"normalization\"]=True #id set to true normalization to the data is apllied, the norm implemented is standardization for SAR data and normalization for RGBNIR\n",
    "train_param[\"training_dir\"]=PATH_TRAININGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_param[\"lim_train_tile\"]=496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove the negative values in order to have no error in the log : negative value will be replaced usingknn algorithm\n",
      "Important the index of the bands in lband_index should be index that follow each other\n",
      "No scaler was defined before\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ba584c7d15b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load data and model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_gan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_param\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/cGAN_sent2_sim/models/clean_gan.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_yaml, train_yaml, data_h5py)\u001b[0m\n\u001b[1;32m     96\u001b[0m                                                                         \u001b[0mfact_s2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfact_s2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfact_s1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfact_s1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                                                                         \u001b[0ms2_bands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2bands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_bands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms1bands\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                                                                         lim=train_yaml[\"lim_train_tile\"])\n\u001b[0m\u001b[1;32m     99\u001b[0m             self.val_X, self.val_Y, scale_dict_val = load_data(self.val_directory, x_shape=model_yaml[\"input_shape\"],\n\u001b[1;32m    100\u001b[0m                                                                \u001b[0mlabel_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_yaml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dim_gt_image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/cGAN_sent2_sim/utils/load_dataset.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path_directory, x_shape, label_shape, normalization, dict_band_X, dict_band_label, dict_rescale_type, dict_scale, fact_s2, fact_s1, s2_bands, s1_bands, clip_s2, lim)\u001b[0m\n\u001b[1;32m     84\u001b[0m                                                       \u001b[0mdict_rescale_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_rescale_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                                       \u001b[0mdict_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2_bands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms2_bands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1_bands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms1_bands\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                                                       fact_scale2=fact_s2, fact_scale1=fact_s1,clip_s2=clip_s2)\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     assert data_label.shape[0] == dataX.shape[0], \"Not the same nber of label {} and dataX {}\".format(label_shape,\n",
      "\u001b[0;32m~/code/cGAN_sent2_sim/utils/normalize.py\u001b[0m in \u001b[0;36mrescale_array\u001b[0;34m(batch_X, batch_label, dict_group_band_X, dict_group_band_label, dict_rescale_type, s1_log, dict_scale, invert, s2_bands, s1_bands, fact_scale2, fact_scale1, clip_s2)\u001b[0m\n\u001b[1;32m    216\u001b[0m             conv1D_dim(data_sar_band.shape))  # Modify into 2D array as required for sklearn\n\u001b[1;32m    217\u001b[0m         output_data, sar_scale = sklearn_scale(dict_rescale_type[group_bands], data_flatten_sar_band,\n\u001b[0;32m--> 218\u001b[0;31m                                                scaler=dict_scale[group_bands], fact_scale=fact_scale1, invert=invert)\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0mrescaled_batch_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_group_band_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_bands\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_shape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reshape it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mdict_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mgroup_bands\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msar_scale\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/cGAN_sent2_sim/utils/normalize.py\u001b[0m in \u001b[0;36msklearn_scale\u001b[0;34m(scaling_method, data, scaler, invert, fact_scale)\u001b[0m\n\u001b[1;32m    263\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfact_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mdata_rescale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_rescale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfact_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'multiply' did not contain a loop with signature matching types (dtype('<U32'), dtype('<U32')) -> dtype('<U32')"
     ]
    }
   ],
   "source": [
    "#load data and model \n",
    "gan=clean_gan.GAN(model_param, train_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check available ressources\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the training\n",
    "model_dir = gan.model_dir\n",
    "training_dir = gan.this_training_dir\n",
    "#saving_yaml(path_model, model_dir)\n",
    "#saving_yaml(path_train, training_dir)\n",
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training_env",
   "language": "python",
   "name": "training_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
